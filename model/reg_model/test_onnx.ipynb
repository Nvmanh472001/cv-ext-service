{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is valid!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "onnx_model = onnx.load(\"./saved_models/recognitionModel.onnx\")\n",
    "try:\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print('The model is invalid: %s' % e)\n",
    "else:\n",
    "    print('The model is valid!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [1.0000, 1.0000, 0.9922,  ..., 0.9843, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 0.9922,  ..., 0.9765, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 0.9922,  ..., 0.9843, 1.0000, 1.0000]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import torch\n",
    "from PIL import Image\n",
    "from utils import NormalizePAD, adjust_contrast_grey\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "image = Image.open(\"all_data/eval_img/7338.jpg\")\n",
    "\n",
    "from utils import reformat_input\n",
    "img, img_cv_gray = reformat_input(image)\n",
    "image = Image.fromarray(img_cv_gray, 'L')\n",
    "\n",
    "transform = NormalizePAD((1, 32, 100))\n",
    "\n",
    "w, h = image.size\n",
    "adjust_contrast = 0.\n",
    "#### augmentation here - change contrast\n",
    "if adjust_contrast > 0:\n",
    "    image = np.array(img_cv_gray.convert(\"L\"))\n",
    "    image = adjust_contrast_grey(image, target = adjust_contrast)\n",
    "    image = Image.fromarray(image, 'L')\n",
    "\n",
    "ratio = w / float(h)\n",
    "if math.ceil(32 * ratio) > 100:\n",
    "    resized_w = 100\n",
    "else:\n",
    "    resized_w = math.ceil(32 * ratio)\n",
    "image = image.resize((resized_w, 32), Image.BICUBIC)\n",
    "image = transform(image)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid rank for input: images_graycay Got: 3 Expected: 4 Please fix either the inputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/misa/Documents/KIE-MISA/OCRFeature/test_onnx.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/misa/Documents/KIE-MISA/OCRFeature/test_onnx.ipynb#ch0000003?line=0'>1</a>\u001b[0m ort_session \u001b[39m=\u001b[39m onnxruntime\u001b[39m.\u001b[39mInferenceSession(\u001b[39m\"\u001b[39m\u001b[39m./saved_models/recognitionModel.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/misa/Documents/KIE-MISA/OCRFeature/test_onnx.ipynb#ch0000003?line=1'>2</a>\u001b[0m ort_inputs \u001b[39m=\u001b[39m {ort_session\u001b[39m.\u001b[39mget_inputs()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mname: to_numpy(image)}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/misa/Documents/KIE-MISA/OCRFeature/test_onnx.ipynb#ch0000003?line=2'>3</a>\u001b[0m ort_outs \u001b[39m=\u001b[39m ort_session\u001b[39m.\u001b[39;49mrun(\u001b[39mNone\u001b[39;49;00m, ort_inputs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/misa/Documents/KIE-MISA/OCRFeature/test_onnx.ipynb#ch0000003?line=3'>4</a>\u001b[0m preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(ort_outs[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:192\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    190\u001b[0m     output_names \u001b[39m=\u001b[39m [output\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_meta]\n\u001b[1;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(output_names, input_feed, run_options)\n\u001b[1;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m C\u001b[39m.\u001b[39mEPFail \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    194\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid rank for input: images_graycay Got: 3 Expected: 4 Please fix either the inputs or the model."
     ]
    }
   ],
   "source": [
    "ort_session = onnxruntime.InferenceSession(\"./saved_models/recognitionModel.onnx\")\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(image)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "preds = torch.from_numpy(ort_outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('3.9.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4e4137ad0b814463a70bb82d69d83e02df7f59a78ae668a2d36f2270425ea85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
